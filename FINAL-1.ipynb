{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/LENOVO/Downloads/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2339a9b08b</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16fab9f95b</td>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>like</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74a76f6e0a</td>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>DANGERously</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04dd1d2e34</td>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bbe3cbf620</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "0   cb774db0d1                I`d have responded, if I were going   \n",
       "1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7   50e14c0bb8                                         Soooo high   \n",
       "8   e050245fbd                                        Both of you   \n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
       "11  16fab9f95b  I really really like the song Love Story by Ta...   \n",
       "12  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
       "13  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n",
       "14  bbe3cbf620                         test test from the LG enV2   \n",
       "\n",
       "                                        selected_text sentiment  \n",
       "0                 I`d have responded, if I were going   neutral  \n",
       "1                                            Sooo SAD  negative  \n",
       "2                                         bullying me  negative  \n",
       "3                                      leave me alone  negative  \n",
       "4                                       Sons of ****,  negative  \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                 fun  positive  \n",
       "7                                          Soooo high   neutral  \n",
       "8                                         Both of you   neutral  \n",
       "9                        Wow... u just became cooler.  positive  \n",
       "10  as much as i love to be hopeful, i reckon the ...   neutral  \n",
       "11                                               like  positive  \n",
       "12                                        DANGERously  negative  \n",
       "13                                               lost  negative  \n",
       "14                         test test from the LG enV2   neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is there any other different value than neutral, negative and positive?\n",
    "train['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>7781</td>\n",
       "      <td>5861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11118</td>\n",
       "      <td>11117</td>\n",
       "      <td>11111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>8582</td>\n",
       "      <td>5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID   text  selected_text\n",
       "sentiment                              \n",
       "negative     7781   7781           5861\n",
       "neutral     11118  11117          11111\n",
       "positive     8582   8582           5537"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How's distributed the dataset? Is it biased?\n",
    "train.groupby('sentiment').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVrUlEQVR4nO3df7RdZX3n8ffHRBGlKCmBwQQaamNbwIpNhqK0HVu6aqbTCmPBxikSlFlpGWTUTqcDnVm1rSstjk4ddSot9QehOmKkdkRXsdJYnI7DD4NSQ0A0Iw5EUog/wWlFg9/5Yz+3HpObcJLn3nu43PdrrbPOPt+zn72fc3fu/WT/ek6qCkmSDtbjJt0BSdL8ZpBIkroYJJKkLgaJJKmLQSJJ6rJ40h2Ya0ceeWStWLFi0t2QpHnllltu+WJVLZ3uvQUXJCtWrGDLli2T7oYkzStJ/u++3vPQliSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKnLgruz/UCs+vdXTroLC8Itrzt30l2Q1ME9EklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldZi1Ikrw9yf1JbhupLUlyXZLPtucjRt67JMn2JHcmef5IfVWSre29NyVJqx+S5D2tflOSFbP1WSRJ+zabeyRXAGv2qF0MbK6qlcDm9pokJwBrgRNbm7ckWdTaXAasB1a2x9Qyzwe+UlU/ALwBeO2sfRJJ0j7NWpBU1f8EvrxH+QxgY5veCJw5Ur+qqh6qqruA7cApSY4BDq+qG6qqgCv3aDO1rKuB06f2ViRJc2euz5EcXVU7AdrzUa2+DLhnZL4drbasTe9Z/642VbUb+BrwvbPWc0nStB4tJ9un25Oo/dT312bvhSfrk2xJsmXXrl0H2UVJ0nTmOkjua4eraM/3t/oO4NiR+ZYD97b68mnq39UmyWLgKex9KA2Aqrq8qlZX1eqlS5fO0EeRJMHcB8k1wLo2vQ54/0h9bbsS63iGk+o3t8NfDyY5tZ3/OHePNlPLOgv4SDuPIkmaQ4tna8FJ3g08DzgyyQ7g1cClwKYk5wN3A2cDVNW2JJuA24HdwIVV9XBb1AUMV4AdClzbHgBvA/40yXaGPZG1s/VZJEn7NmtBUlUv3sdbp+9j/g3AhmnqW4CTpql/gxZEkqTJebScbJckzVMGiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLosn3QFJ2tNpbz5t0l1YED520cdmZDnukUiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKnLRIIkyauSbEtyW5J3J3likiVJrkvy2fZ8xMj8lyTZnuTOJM8fqa9KsrW996YkmcTnkaSFbM6DJMky4N8Cq6vqJGARsBa4GNhcVSuBze01SU5o758IrAHekmRRW9xlwHpgZXusmcOPIklicoe2FgOHJlkMPAm4FzgD2Nje3wic2abPAK6qqoeq6i5gO3BKkmOAw6vqhqoq4MqRNpKkOTLnQVJVXwBeD9wN7AS+VlUfBo6uqp1tnp3AUa3JMuCekUXsaLVlbXrP+l6SrE+yJcmWXbt2zeTHkaQFbxKHto5g2Ms4Hnga8OQk5+yvyTS12k9972LV5VW1uqpWL1269EC7LEnaj0kc2voZ4K6q2lVV3wLeBzwXuK8drqI939/m3wEcO9J+OcOhsB1tes+6JGkOTSJI7gZOTfKkdpXV6cAdwDXAujbPOuD9bfoaYG2SQ5Icz3BS/eZ2+OvBJKe25Zw70kaSNEfmfBj5qropydXAJ4DdwCeBy4HDgE1JzmcIm7Pb/NuSbAJub/NfWFUPt8VdAFwBHApc2x4SAHf/7jMn3YXHvON+a+uku6BHgYl8H0lVvRp49R7lhxj2TqabfwOwYZr6FuCkGe+gJGls3tkuSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC5jBUmSzePUJEkLz+L9vZnkicCTgCOTHAGkvXU48LRZ7pskaR7Yb5AAvwK8kiE0buE7QfIA8Iez1y1J0nyx3yCpqjcCb0xyUVW9eY76JEmaRx5pjwSAqnpzkucCK0bbVNWVs9QvSdI8Me7J9j8FXg/8OPBP22P1wa40yVOTXJ3k00nuSPKcJEuSXJfks+35iJH5L0myPcmdSZ4/Ul+VZGt7701JMv0aJUmzZaw9EobQOKGqaobW+0bgQ1V1VpInMJzQ/01gc1VdmuRi4GLgPyQ5AVgLnMhwruavkjyjqh4GLgPWAzcCfwGsAa6doT5KksYw7n0ktwH/ZCZWmORw4CeBtwFU1Ter6qvAGcDGNttG4Mw2fQZwVVU9VFV3AduBU5IcAxxeVTe0gLtypI0kaY6Mu0dyJHB7kpuBh6aKVfWCg1jn9wO7gHckeRbD1WCvAI6uqp1tuTuTHNXmX8awxzFlR6t9q03vWd9LkvUMey4cd9xxB9FlSdK+jBskvz3D6/xR4KKquinJGxkOY+3LdOc9aj/1vYtVlwOXA6xevXqmDs9Jkhj/qq2PzuA6dwA7quqm9vpqhiC5L8kxbW/kGOD+kfmPHWm/HLi31ZdPU5ckzaFxr9p6MMkD7fGNJA8neeBgVlhVfwfck+QHW+l04HbgGmBdq60D3t+mrwHWJjkkyfHASuDmdhjswSSntqu1zh1pI0maI+PukXzP6OskZwKndKz3IuBd7YqtzwEvZQi1TUnOB+4Gzm7r3pZkE0PY7AYubFdsAVwAXAEcynC1lldsSdIcG/ccyXepqv/RLtE9KFV1K9Pfh3L6PubfAGyYpr4FOOlg+yFJ6jdWkCR54cjLxzGEgCetJUlj75H8wsj0buDzDPd3SJIWuHHPkbx0tjsiSZqfxr1qa3mSP09yf5L7kvxZkuWP3FKS9Fg37hAp72C4DPdpDHePf6DVJEkL3LhBsrSq3lFVu9vjCmDpLPZLkjRPjBskX0xyTpJF7XEO8KXZ7JgkaX4YN0heBrwI+DtgJ3AWw02EkqQFbtzLf18DrKuqrwAkWcLwRVcvm62OSZLmh3H3SH5kKkQAqurLwLNnp0uSpPlk3CB53B5ffbuEgxxeRZL02DJuGPwX4H8nuZphaJQXMc3YV5KkhWfcO9uvTLIF+GmGL5R6YVXdPqs9kyTNC2MfnmrBYXhIkr7LuOdIJEmalkEiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSeoysSBJsijJJ5N8sL1ekuS6JJ9tz6PfyHhJku1J7kzy/JH6qiRb23tvSpJJfBZJWsgmuUfyCuCOkdcXA5uraiWwub0myQnAWuBEYA3wliSLWpvLgPXAyvZYMzddlyRNmUiQJFkO/AvgrSPlM4CNbXojcOZI/aqqeqiq7gK2A6ckOQY4vKpuqKoCrhxpI0maI5PaI/mvwG8A3x6pHV1VOwHa81Gtvgy4Z2S+Ha22rE3vWd9LkvVJtiTZsmvXrhn5AJKkwZwHSZKfB+6vqlvGbTJNrfZT37tYdXlVra6q1UuXLh1ztZKkcYz9ne0z6DTgBUl+DngicHiSdwL3JTmmqna2w1b3t/l3AMeOtF8O3Nvqy6epS5Lm0JzvkVTVJVW1vKpWMJxE/0hVnQNcA6xrs60D3t+mrwHWJjkkyfEMJ9Vvboe/Hkxyarta69yRNpKkOTKJPZJ9uRTYlOR84G7gbICq2pZkE3A7sBu4sKoebm0uAK4ADgWubQ9J0hyaaJBU1fXA9W36S8Dp+5hvA7BhmvoW4KTZ66Ek6ZF4Z7skqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLnMeJEmOTfLXSe5Isi3JK1p9SZLrkny2PR8x0uaSJNuT3Jnk+SP1VUm2tvfelCRz/XkkaaGbxB7JbuDfVdUPA6cCFyY5AbgY2FxVK4HN7TXtvbXAicAa4C1JFrVlXQasB1a2x5q5/CCSpAkESVXtrKpPtOkHgTuAZcAZwMY220bgzDZ9BnBVVT1UVXcB24FTkhwDHF5VN1RVAVeOtJEkzZGJniNJsgJ4NnATcHRV7YQhbICj2mzLgHtGmu1otWVtes+6JGkOTSxIkhwG/Bnwyqp6YH+zTlOr/dSnW9f6JFuSbNm1a9eBd1aStE8TCZIkj2cIkXdV1fta+b52uIr2fH+r7wCOHWm+HLi31ZdPU99LVV1eVauravXSpUtn7oNIkiZy1VaAtwF3VNUfjLx1DbCuTa8D3j9SX5vkkCTHM5xUv7kd/nowyaltmeeOtJEkzZHFE1jnacBLgK1Jbm213wQuBTYlOR+4GzgboKq2JdkE3M5wxdeFVfVwa3cBcAVwKHBte0iS5tCcB0lV/S+mP78BcPo+2mwANkxT3wKcNHO9kyQdKO9slyR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdZn3QZJkTZI7k2xPcvGk+yNJC828DpIki4A/BP45cALw4iQnTLZXkrSwzOsgAU4BtlfV56rqm8BVwBkT7pMkLSipqkn34aAlOQtYU1X/ur1+CfBjVfXyPeZbD6xvL38QuHNOOzq3jgS+OOlO6KC47ea3x/r2+76qWjrdG4vnuiczLNPU9krGqrocuHz2uzN5SbZU1epJ90MHzm03vy3k7TffD23tAI4deb0cuHdCfZGkBWm+B8nHgZVJjk/yBGAtcM2E+yRJC8q8PrRVVbuTvBz4S2AR8Paq2jbhbk3agjiE9xjltpvfFuz2m9cn2yVJkzffD21JkibMIJEkdTFIHoOSrEjyrw6y7ddnuj86cEmemuTfjLx+WpKrJ9knTS/JryY5t02fl+RpI++9dSGMtuE5ksegJM8Dfr2qfn6a9xZX1e79tP16VR02i93TGJKsAD5YVSdNui8aX5LrGX73tky6L3PJPZJHkbYncUeSP0myLcmHkxya5OlJPpTkliR/k+SH2vxXtLv7p9pP7U1cCvxEkluTvKr9L+m9ST4AfDjJYUk2J/lEkq1JHFbmAB3Etnp6khuTfDzJ705tq/1si0uBp7dt+Lq2vttam5uSnDjSl+uTrEry5CRvb+v4pNv1kbWf66eTbEzyqSRXJ3lSktPbz3Br+5ke0ua/NMntbd7Xt9pvJ/n19ru4GnhX226Htm2zOskFSf7zyHrPS/LmNn1Okptbmz9uYwjOL1Xl41HyAFYAu4GT2+tNwDnAZmBlq/0Y8JE2fQVw1kj7r7fn5zH8b3aqfh7DzZtL2uvFwOFt+khgO9/ZO/36pH8O8+FxENvqg8CL2/SvjmyrabdFW/5te6zvtjb9KuB32vQxwGfa9O8B57TppwKfAZ486Z/Vo/nRfq4FnNZevx34T8A9wDNa7UrglcAShuGVpn5Xntqef5thLwTgemD1yPKvZwiXpQzjAk7VrwV+HPhh4APA41v9LcC5k/65HOjDPZJHn7uq6tY2fQvDP/TnAu9Ncivwxwx/PA7UdVX15TYd4PeSfAr4K2AZcHRHnxeqA9lWzwHe26b/+8gyDmZbbALObtMvGlnuzwIXt3VfDzwROO7APtKCdE9VfaxNvxM4nWHbfqbVNgI/CTwAfAN4a5IXAn8/7gqqahfwuSSnJvlehjH/PtbWtQr4eNtupwPf3/+R5ta8viHxMeqhkemHGf6ofLWqTp5m3t20w5NJAjxhP8v9fyPTv8zwP6RVVfWtJJ9n+KOjA3Mg22pfDnhbVNUXknwpyY8AvwT8SnsrwC9W1WN5UNLZMNaJ4hpugD6F4Y/9WuDlwE8fwHrewxD8nwb+vKqq/d5urKpLDrDPjyrukTz6PQDcleRsGAIjybPae59n+N8MDMPnP75NPwh8z36W+RTg/vaH66eA75vxXi9M+9tWNwK/2KbXjrTZ17Z4pG14FfAbwFOqamur/SVwUfvjRJJn936gBeK4JM9p0y9m2DNckeQHWu0lwEeTHMbw8/4LhkNdJ0+zrP1tt/cBZ7Z1vKfVNgNnJTkKIMmSJPPu99EgmR9+GTg/yd8C2/jOd678CfDPktzMcDx+aq/jU8DuJH+b5FXTLO9dwOokW9qyPz2rvV9Y9rWtXgn8WttWxwBfa/Vpt0VVfQn4WJLbkrxumvVczRBIm0Zqr2H4z8Sn2on518zkB3sMuwNY1w4vLgHeALyU4RDlVuDbwB8xBMQH23wfZThXtacrgD+aOtk++kZVfQW4nWE49ptb7XaGczIfbsu9joM7dD1RXv4rzYEkTwL+oR3OWMtw4t2rqiYsXmY9IzxHIs2NVcB/a4edvgq8bLLdkWaOeySSpC6eI5EkdTFIJEldDBJJUheDRJpDSU5O8nMjr1+Q5OJZXufzkjx3Ntehhc0gkebWycA/BklVXVNVl87yOp/HMHSLNCu8aksaU5InM9wAuBxYxHDD33bgD4DDgC8C51XVzgzDid8E/BTDAIrnt9fbgUOBLwC/36ZXV9XLk1wB/APwQwx3uL8UWMcwTtdNVXVe68fPAr8DHAL8H+ClVfX1NrzKRuAXGG5MPJthbKgbGYZw2QVcVFV/Mws/Hi1g7pFI41sD3FtVz2o3sH0IeDPDCMyrGEaO3TAy/+KqOoXhrvZXV9U3gd8C3lNVJ1fVe9jbEQzjN72KYVTYNwAnAs9sh8WOZLgT+meq6keBLcCvjbT/YqtfxjAi7ecZ7sp+Q1unIaIZ5w2J0vi2Aq9P8lqGYeG/ApwEXNeGt1oE7ByZ/33teWpk4HF8oN39vhW4b2ocrSTb2jKWAycwDJ8Cw0CdN+xjnS88gM8mHTSDRBpTVX0mySqGcxy/zzAu0raqes4+mkyNDvww4/+uTbX5Nt89uvC32zIeZvhKgBfP4DqlLh7aksaU4bu4/76q3gm8nmGgzKVTI8cmefzoNxfuwyON6vtIbgROmxqZtn2b3zNmeZ3Sfhkk0vieCdzcvoDoPzKc7zgLeG0b7fdWHvnqqL8GTmijw/7SgXagfUHSecC722ixNzKcnN+fDwD/sq3zJw50ndIj8aotSVIX90gkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLU5f8D6xaKDEDG9CgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for data imbalance\n",
    "sns.countplot(train[\"sentiment\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         selected_text sentiment\n",
       "0  I`d have responded, if I were going   neutral\n",
       "1                             Sooo SAD  negative\n",
       "2                          bullying me  negative\n",
       "3                       leave me alone  negative\n",
       "4                        Sons of ****,  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's keep only the columns that we're going to use\n",
    "train = train[['selected_text','sentiment']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is there any null value?\n",
    "train[\"selected_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fill the only null value.\n",
    "train[\"selected_text\"].fillna(\"No content\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I`d have responded, if I were going',\n",
       " 'Sooo SAD',\n",
       " 'bullying me',\n",
       " 'leave me alone',\n",
       " 'Sons of ****,']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = train['selected_text'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['have', 'responded', 'if', 'were', 'going'], ['sooo', 'sad'], ['bullying', 'me'], ['leave', 'me', 'alone'], ['sons', 'of'], ['some', 'shameless', 'plugging', 'for', 'the', 'best', 'rangers', 'forum', 'on', 'earth'], ['fun'], ['soooo', 'high'], ['both', 'of', 'you'], ['wow', 'just', 'became', 'cooler']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have responded if were going', 'sooo sad', 'bullying me', 'leave me alone', 'sons of']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['sentiment'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sequencing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   68  146   41]\n",
      " [   0    0    0 ...    0  397   65]\n",
      " [   0    0    0 ...    0    0   11]\n",
      " ...\n",
      " [   0    0    0 ...  372   10    3]\n",
      " [   0    0    0 ...   24  542    4]\n",
      " [   0    0    0 ... 2424  199  657]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20610 6871 20610 6871\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SimpleRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "645/645 [==============================] - 17s 25ms/step - loss: 0.8271 - accuracy: 0.6333\n",
      "Epoch 2/30\n",
      "645/645 [==============================] - 18s 28ms/step - loss: 0.4066 - accuracy: 0.8534\n",
      "Epoch 3/30\n",
      "645/645 [==============================] - 21s 32ms/step - loss: 0.3317 - accuracy: 0.8821\n",
      "Epoch 4/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.2579 - accuracy: 0.9102\n",
      "Epoch 5/30\n",
      "645/645 [==============================] - 21s 32ms/step - loss: 0.1965 - accuracy: 0.9328\n",
      "Epoch 6/30\n",
      "645/645 [==============================] - 21s 32ms/step - loss: 0.2364 - accuracy: 0.9171\n",
      "Epoch 7/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1503 - accuracy: 0.9468\n",
      "Epoch 8/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1562 - accuracy: 0.9441\n",
      "Epoch 9/30\n",
      "645/645 [==============================] - 21s 32ms/step - loss: 0.1182 - accuracy: 0.9587\n",
      "Epoch 10/30\n",
      "645/645 [==============================] - 21s 32ms/step - loss: 0.2305 - accuracy: 0.9196\n",
      "Epoch 11/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1468 - accuracy: 0.9459\n",
      "Epoch 12/30\n",
      "645/645 [==============================] - 22s 33ms/step - loss: 0.1157 - accuracy: 0.9603\n",
      "Epoch 13/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1109 - accuracy: 0.9599\n",
      "Epoch 14/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1102 - accuracy: 0.9620\n",
      "Epoch 15/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1540 - accuracy: 0.9440\n",
      "Epoch 16/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1322 - accuracy: 0.9522\n",
      "Epoch 17/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1073 - accuracy: 0.9623\n",
      "Epoch 18/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1172 - accuracy: 0.9559\n",
      "Epoch 19/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1043 - accuracy: 0.9618\n",
      "Epoch 20/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0982 - accuracy: 0.9631\n",
      "Epoch 21/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0912 - accuracy: 0.9684\n",
      "Epoch 22/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1310 - accuracy: 0.9552\n",
      "Epoch 23/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0938 - accuracy: 0.9655\n",
      "Epoch 24/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0815 - accuracy: 0.9700\n",
      "Epoch 25/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0813 - accuracy: 0.9684\n",
      "Epoch 26/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.1007 - accuracy: 0.9639\n",
      "Epoch 27/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0851 - accuracy: 0.9686\n",
      "Epoch 28/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0807 - accuracy: 0.9695\n",
      "Epoch 29/30\n",
      "645/645 [==============================] - 21s 33ms/step - loss: 0.0774 - accuracy: 0.9691\n",
      "Epoch 30/30\n",
      "645/645 [==============================] - 22s 34ms/step - loss: 0.0973 - accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model0 = Sequential()\n",
    "model0.add(layers.Embedding(max_words, 50))\n",
    "model0.add(layers.SimpleRNN(50))\n",
    "model0.add(Dropout(0.2))\n",
    "model0.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model0.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model0.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 1s - loss: 1.1946 - accuracy: 0.7648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1945754289627075, 0.7648085951805115]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model0.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.750524\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 0.751273\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('recall score: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.762273\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('precision score: %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Single LSTM layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "645/645 [==============================] - 27s 39ms/step - loss: 0.8695 - accuracy: 0.6221\n",
      "Epoch 2/50\n",
      "645/645 [==============================] - 25s 39ms/step - loss: 0.5030 - accuracy: 0.8042\n",
      "Epoch 3/50\n",
      "645/645 [==============================] - 27s 43ms/step - loss: 0.4337 - accuracy: 0.8346\n",
      "Epoch 4/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.4056 - accuracy: 0.8477\n",
      "Epoch 5/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3828 - accuracy: 0.8584\n",
      "Epoch 6/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3644 - accuracy: 0.8665\n",
      "Epoch 7/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3499 - accuracy: 0.8703\n",
      "Epoch 8/50\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.3425 - accuracy: 0.8770\n",
      "Epoch 9/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3341 - accuracy: 0.8797\n",
      "Epoch 10/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.3223 - accuracy: 0.8849\n",
      "Epoch 11/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.3147 - accuracy: 0.8846\n",
      "Epoch 12/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3121 - accuracy: 0.8874\n",
      "Epoch 13/50\n",
      "645/645 [==============================] - 27s 43ms/step - loss: 0.3042 - accuracy: 0.8899\n",
      "Epoch 14/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2977 - accuracy: 0.8901\n",
      "Epoch 15/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.2889 - accuracy: 0.8938\n",
      "Epoch 16/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2803 - accuracy: 0.8991\n",
      "Epoch 17/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2834 - accuracy: 0.8962\n",
      "Epoch 18/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2723 - accuracy: 0.9002\n",
      "Epoch 19/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2700 - accuracy: 0.9019\n",
      "Epoch 20/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2601 - accuracy: 0.9066\n",
      "Epoch 21/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2678 - accuracy: 0.9033\n",
      "Epoch 22/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2509 - accuracy: 0.9097\n",
      "Epoch 23/50\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.2529 - accuracy: 0.9096\n",
      "Epoch 24/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2463 - accuracy: 0.9099\n",
      "Epoch 25/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.2506 - accuracy: 0.9124\n",
      "Epoch 26/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2349 - accuracy: 0.9154\n",
      "Epoch 27/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2327 - accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "645/645 [==============================] - 27s 43ms/step - loss: 0.2234 - accuracy: 0.9190\n",
      "Epoch 29/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.2217 - accuracy: 0.9206\n",
      "Epoch 30/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.2159 - accuracy: 0.9220\n",
      "Epoch 31/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.2113 - accuracy: 0.9269\n",
      "Epoch 32/50\n",
      "645/645 [==============================] - 27s 43ms/step - loss: 0.2040 - accuracy: 0.9273\n",
      "Epoch 33/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1959 - accuracy: 0.9298\n",
      "Epoch 34/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1909 - accuracy: 0.9312\n",
      "Epoch 35/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1901 - accuracy: 0.9306\n",
      "Epoch 36/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1869 - accuracy: 0.9335\n",
      "Epoch 37/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1847 - accuracy: 0.9353\n",
      "Epoch 38/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.1808 - accuracy: 0.9359\n",
      "Epoch 39/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1813 - accuracy: 0.9349\n",
      "Epoch 40/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1661 - accuracy: 0.9418\n",
      "Epoch 41/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1696 - accuracy: 0.9399\n",
      "Epoch 42/50\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.1598 - accuracy: 0.9428\n",
      "Epoch 43/50\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.1628 - accuracy: 0.9438\n",
      "Epoch 44/50\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.1641 - accuracy: 0.9423\n",
      "Epoch 45/50\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.1620 - accuracy: 0.9421\n",
      "Epoch 46/50\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.1635 - accuracy: 0.9441\n",
      "Epoch 47/50\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.1514 - accuracy: 0.9478\n",
      "Epoch 48/50\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.1500 - accuracy: 0.9478\n",
      "Epoch 49/50\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.1477 - accuracy: 0.9497\n",
      "Epoch 50/50\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.1501 - accuracy: 0.9486\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(20))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model1.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 2s - loss: 0.6483 - accuracy: 0.8086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6482827067375183, 0.8086159229278564]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model1.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.808658\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 0.808616\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test.argmax(axis=1), yhat_classes,average='weighted')\n",
    "print('recall score: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.809087\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test.argmax(axis=1),yhat_classes,average='weighted')\n",
    "print('precision score: %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bidirectional LTSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "645/645 [==============================] - 43s 61ms/step - loss: 0.8354 - accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.4870 - accuracy: 0.8103\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.4122 - accuracy: 0.8494\n",
      "Epoch 4/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3867 - accuracy: 0.8584\n",
      "Epoch 5/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.3730 - accuracy: 0.8643\n",
      "Epoch 6/100\n",
      "645/645 [==============================] - 45s 71ms/step - loss: 0.3521 - accuracy: 0.8730\n",
      "Epoch 7/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3441 - accuracy: 0.8748\n",
      "Epoch 8/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3325 - accuracy: 0.8784\n",
      "Epoch 9/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3256 - accuracy: 0.8818\n",
      "Epoch 10/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.3068 - accuracy: 0.8879\n",
      "Epoch 11/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3053 - accuracy: 0.8896\n",
      "Epoch 12/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2911 - accuracy: 0.8956\n",
      "Epoch 13/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2871 - accuracy: 0.8976\n",
      "Epoch 14/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2754 - accuracy: 0.9025\n",
      "Epoch 15/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.2625 - accuracy: 0.9072\n",
      "Epoch 16/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2638 - accuracy: 0.9042\n",
      "Epoch 17/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2619 - accuracy: 0.9057\n",
      "Epoch 18/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.2553 - accuracy: 0.9088\n",
      "Epoch 19/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2401 - accuracy: 0.9158\n",
      "Epoch 20/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.2372 - accuracy: 0.9148\n",
      "Epoch 21/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.2256 - accuracy: 0.9206\n",
      "Epoch 22/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.2243 - accuracy: 0.9245\n",
      "Epoch 23/100\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.2185 - accuracy: 0.9235\n",
      "Epoch 24/100\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.2096 - accuracy: 0.9275\n",
      "Epoch 25/100\n",
      "645/645 [==============================] - 49s 76ms/step - loss: 0.2021 - accuracy: 0.9304\n",
      "Epoch 26/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.1997 - accuracy: 0.9322\n",
      "Epoch 27/100\n",
      "645/645 [==============================] - 49s 75ms/step - loss: 0.1994 - accuracy: 0.9292\n",
      "Epoch 28/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1869 - accuracy: 0.9345\n",
      "Epoch 29/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1827 - accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1752 - accuracy: 0.9396\n",
      "Epoch 31/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1754 - accuracy: 0.9390\n",
      "Epoch 32/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.1686 - accuracy: 0.9421\n",
      "Epoch 33/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1656 - accuracy: 0.9445\n",
      "Epoch 34/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1575 - accuracy: 0.94590s - loss: 0.1575 - \n",
      "Epoch 35/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1494 - accuracy: 0.9490\n",
      "Epoch 36/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1556 - accuracy: 0.9471\n",
      "Epoch 37/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1452 - accuracy: 0.9508\n",
      "Epoch 38/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1433 - accuracy: 0.9507\n",
      "Epoch 39/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1419 - accuracy: 0.9514\n",
      "Epoch 40/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1353 - accuracy: 0.9545\n",
      "Epoch 41/100\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.1344 - accuracy: 0.9558\n",
      "Epoch 42/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1311 - accuracy: 0.9547\n",
      "Epoch 43/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1262 - accuracy: 0.9561\n",
      "Epoch 44/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1269 - accuracy: 0.9570\n",
      "Epoch 45/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1234 - accuracy: 0.9571\n",
      "Epoch 46/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1245 - accuracy: 0.9579\n",
      "Epoch 47/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1124 - accuracy: 0.9617\n",
      "Epoch 48/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1181 - accuracy: 0.9607\n",
      "Epoch 49/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.1100 - accuracy: 0.9649\n",
      "Epoch 50/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.1151 - accuracy: 0.9612\n",
      "Epoch 51/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1020 - accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1047 - accuracy: 0.9650\n",
      "Epoch 53/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.1018 - accuracy: 0.9664\n",
      "Epoch 54/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.1080 - accuracy: 0.9636\n",
      "Epoch 55/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.1013 - accuracy: 0.9670\n",
      "Epoch 56/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.0977 - accuracy: 0.9665\n",
      "Epoch 57/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0921 - accuracy: 0.9690\n",
      "Epoch 58/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.0983 - accuracy: 0.9681\n",
      "Epoch 59/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0978 - accuracy: 0.9662\n",
      "Epoch 60/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0960 - accuracy: 0.9654\n",
      "Epoch 61/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.0929 - accuracy: 0.9681\n",
      "Epoch 62/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0911 - accuracy: 0.9690\n",
      "Epoch 63/100\n",
      "645/645 [==============================] - 46s 72ms/step - loss: 0.0936 - accuracy: 0.9686\n",
      "Epoch 64/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0856 - accuracy: 0.9712\n",
      "Epoch 65/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.0875 - accuracy: 0.9715\n",
      "Epoch 66/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.0882 - accuracy: 0.9714\n",
      "Epoch 67/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0872 - accuracy: 0.9710\n",
      "Epoch 68/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0834 - accuracy: 0.9727\n",
      "Epoch 69/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0823 - accuracy: 0.9722\n",
      "Epoch 70/100\n",
      "645/645 [==============================] - 46s 72ms/step - loss: 0.0763 - accuracy: 0.9736\n",
      "Epoch 71/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.0810 - accuracy: 0.9735\n",
      "Epoch 72/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.0819 - accuracy: 0.9734\n",
      "Epoch 73/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0814 - accuracy: 0.9725\n",
      "Epoch 74/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0784 - accuracy: 0.9739\n",
      "Epoch 75/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0845 - accuracy: 0.9717\n",
      "Epoch 76/100\n",
      "645/645 [==============================] - 46s 72ms/step - loss: 0.0837 - accuracy: 0.9728\n",
      "Epoch 77/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.0783 - accuracy: 0.9748\n",
      "Epoch 78/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.0773 - accuracy: 0.9740\n",
      "Epoch 79/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.0733 - accuracy: 0.9750\n",
      "Epoch 80/100\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.0740 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.0747 - accuracy: 0.9755\n",
      "Epoch 82/100\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.0714 - accuracy: 0.9768\n",
      "Epoch 83/100\n",
      "645/645 [==============================] - 45s 69ms/step - loss: 0.0682 - accuracy: 0.9766\n",
      "Epoch 84/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.0714 - accuracy: 0.9753\n",
      "Epoch 85/100\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.0706 - accuracy: 0.9768\n",
      "Epoch 86/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.0720 - accuracy: 0.9761\n",
      "Epoch 87/100\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.0734 - accuracy: 0.9753\n",
      "Epoch 88/100\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.0690 - accuracy: 0.9757\n",
      "Epoch 89/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0665 - accuracy: 0.9773\n",
      "Epoch 90/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0681 - accuracy: 0.9765\n",
      "Epoch 91/100\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.0677 - accuracy: 0.9765\n",
      "Epoch 92/100\n",
      "645/645 [==============================] - 46s 72ms/step - loss: 0.0652 - accuracy: 0.9784\n",
      "Epoch 93/100\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.0638 - accuracy: 0.9787\n",
      "Epoch 94/100\n",
      "645/645 [==============================] - 46s 72ms/step - loss: 0.0677 - accuracy: 0.9765\n",
      "Epoch 95/100\n",
      "645/645 [==============================] - 46s 71ms/step - loss: 0.0647 - accuracy: 0.9779\n",
      "Epoch 96/100\n",
      "645/645 [==============================] - 49s 77ms/step - loss: 0.0635 - accuracy: 0.9777\n",
      "Epoch 97/100\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.0703 - accuracy: 0.9769\n",
      "Epoch 98/100\n",
      "645/645 [==============================] - 52s 81ms/step - loss: 0.0617 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.0675 - accuracy: 0.9763\n",
      "Epoch 100/100\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.0645 - accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 3s - loss: 1.2374 - accuracy: 0.7620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2373535633087158, 0.7620433568954468]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model2.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.761175\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 0.762043\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('recall score: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.764130\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('precision score: %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 1D Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "645/645 [==============================] - 7s 9ms/step - loss: 1.2714 - acc: 0.4534\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.8750 - acc: 0.6070\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.8238 - acc: 0.6278\n",
      "Epoch 4/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.7561 - acc: 0.7159\n",
      "Epoch 5/100\n",
      "645/645 [==============================] - 8s 12ms/step - loss: 0.6271 - acc: 0.7881\n",
      "Epoch 6/100\n",
      "645/645 [==============================] - 8s 13ms/step - loss: 0.5454 - acc: 0.8226\n",
      "Epoch 7/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.5332 - acc: 0.8269\n",
      "Epoch 8/100\n",
      "645/645 [==============================] - 8s 12ms/step - loss: 0.4983 - acc: 0.8438\n",
      "Epoch 9/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.4898 - acc: 0.8438\n",
      "Epoch 10/100\n",
      "645/645 [==============================] - 8s 12ms/step - loss: 0.4682 - acc: 0.8549\n",
      "Epoch 11/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.4535 - acc: 0.8620\n",
      "Epoch 12/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.4429 - acc: 0.8671\n",
      "Epoch 13/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.4408 - acc: 0.8634\n",
      "Epoch 14/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.4420 - acc: 0.8634\n",
      "Epoch 15/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.4245 - acc: 0.8723\n",
      "Epoch 16/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.4251 - acc: 0.8695\n",
      "Epoch 17/100\n",
      "645/645 [==============================] - 7s 12ms/step - loss: 0.4202 - acc: 0.8721\n",
      "Epoch 18/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.4186 - acc: 0.8739\n",
      "Epoch 19/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.4129 - acc: 0.8748\n",
      "Epoch 20/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.4085 - acc: 0.8764\n",
      "Epoch 21/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3921 - acc: 0.8820\n",
      "Epoch 22/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3990 - acc: 0.8812\n",
      "Epoch 23/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.4018 - acc: 0.8822\n",
      "Epoch 24/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.4010 - acc: 0.8803\n",
      "Epoch 25/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3970 - acc: 0.8802\n",
      "Epoch 26/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3885 - acc: 0.8835\n",
      "Epoch 27/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3798 - acc: 0.8859\n",
      "Epoch 28/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3904 - acc: 0.8814\n",
      "Epoch 29/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3836 - acc: 0.8849\n",
      "Epoch 30/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3833 - acc: 0.8841\n",
      "Epoch 31/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3724 - acc: 0.8881\n",
      "Epoch 32/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3622 - acc: 0.8949\n",
      "Epoch 33/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3733 - acc: 0.8894\n",
      "Epoch 34/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3672 - acc: 0.8913\n",
      "Epoch 35/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3685 - acc: 0.8919\n",
      "Epoch 36/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3674 - acc: 0.8935A: 1s \n",
      "Epoch 37/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3685 - acc: 0.8888\n",
      "Epoch 38/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3617 - acc: 0.8945\n",
      "Epoch 39/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3544 - acc: 0.8994\n",
      "Epoch 40/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3646 - acc: 0.8951\n",
      "Epoch 41/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3495 - acc: 0.8959\n",
      "Epoch 42/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3519 - acc: 0.8971\n",
      "Epoch 43/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3543 - acc: 0.8966\n",
      "Epoch 44/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3481 - acc: 0.8988\n",
      "Epoch 45/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3528 - acc: 0.8970\n",
      "Epoch 46/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3428 - acc: 0.9032\n",
      "Epoch 47/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3463 - acc: 0.8993\n",
      "Epoch 48/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3451 - acc: 0.9023\n",
      "Epoch 49/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3389 - acc: 0.9030\n",
      "Epoch 50/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3363 - acc: 0.9017\n",
      "Epoch 51/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3286 - acc: 0.9080\n",
      "Epoch 52/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3391 - acc: 0.9034\n",
      "Epoch 53/100\n",
      "645/645 [==============================] - 8s 12ms/step - loss: 0.3236 - acc: 0.9074\n",
      "Epoch 54/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3348 - acc: 0.9051\n",
      "Epoch 55/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3233 - acc: 0.9099\n",
      "Epoch 56/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3242 - acc: 0.9085\n",
      "Epoch 57/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3276 - acc: 0.9083\n",
      "Epoch 58/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3224 - acc: 0.9076\n",
      "Epoch 59/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3195 - acc: 0.9132\n",
      "Epoch 60/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3245 - acc: 0.9100\n",
      "Epoch 61/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3197 - acc: 0.9092\n",
      "Epoch 62/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3187 - acc: 0.9101\n",
      "Epoch 63/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3155 - acc: 0.9118\n",
      "Epoch 64/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3069 - acc: 0.9202\n",
      "Epoch 65/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3200 - acc: 0.9105\n",
      "Epoch 66/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.3132 - acc: 0.9134\n",
      "Epoch 67/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3076 - acc: 0.9196\n",
      "Epoch 68/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3105 - acc: 0.9180\n",
      "Epoch 69/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.3148 - acc: 0.9158\n",
      "Epoch 70/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3069 - acc: 0.9154\n",
      "Epoch 71/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3015 - acc: 0.9212\n",
      "Epoch 72/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3098 - acc: 0.9173\n",
      "Epoch 73/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.3048 - acc: 0.9174\n",
      "Epoch 74/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2926 - acc: 0.9237: 0s - loss: 0.2918 - \n",
      "Epoch 75/100\n",
      "645/645 [==============================] - 8s 13ms/step - loss: 0.2935 - acc: 0.9210\n",
      "Epoch 76/100\n",
      "645/645 [==============================] - 9s 13ms/step - loss: 0.3011 - acc: 0.9190: 0s - loss: 0.30\n",
      "Epoch 77/100\n",
      "645/645 [==============================] - 8s 12ms/step - loss: 0.3004 - acc: 0.9216\n",
      "Epoch 78/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2958 - acc: 0.9205\n",
      "Epoch 79/100\n",
      "645/645 [==============================] - 7s 12ms/step - loss: 0.3007 - acc: 0.9194\n",
      "Epoch 80/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2901 - acc: 0.9248\n",
      "Epoch 81/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2913 - acc: 0.9226\n",
      "Epoch 82/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2941 - acc: 0.9239\n",
      "Epoch 83/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2879 - acc: 0.9250\n",
      "Epoch 84/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2879 - acc: 0.9266\n",
      "Epoch 85/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2782 - acc: 0.9279\n",
      "Epoch 86/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2901 - acc: 0.9252\n",
      "Epoch 87/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2819 - acc: 0.9275\n",
      "Epoch 88/100\n",
      "645/645 [==============================] - 8s 13ms/step - loss: 0.2790 - acc: 0.9281\n",
      "Epoch 89/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2781 - acc: 0.9290\n",
      "Epoch 90/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2823 - acc: 0.9257\n",
      "Epoch 91/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.2835 - acc: 0.9255\n",
      "Epoch 92/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2770 - acc: 0.9275\n",
      "Epoch 93/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2790 - acc: 0.9284\n",
      "Epoch 94/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.2709 - acc: 0.9289\n",
      "Epoch 95/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2791 - acc: 0.9275\n",
      "Epoch 96/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2783 - acc: 0.9292\n",
      "Epoch 97/100\n",
      "645/645 [==============================] - 7s 11ms/step - loss: 0.2675 - acc: 0.9343\n",
      "Epoch 98/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.2765 - acc: 0.9298\n",
      "Epoch 99/100\n",
      "645/645 [==============================] - 6s 10ms/step - loss: 0.2655 - acc: 0.9340\n",
      "Epoch 100/100\n",
      "645/645 [==============================] - 7s 10ms/step - loss: 0.2706 - acc: 0.9313\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.MaxPooling1D(5))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(3,activation='softmax'))\n",
    "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "history = model3.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 1s - loss: 0.6607 - acc: 0.8189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6606921553611755, 0.8189492225646973]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model3.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.818884\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test.argmax(axis=1), yhat_classes.astype(np.int),average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 0.818949\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_tests, yhat_classes,average='weighted')\n",
    "print('recall score: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.821187\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_tests, yhat_classes,average='weighted')\n",
    "print('precision score: %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall results are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>Precision_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SimpleRNN model</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single LSTM layer model</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bidirectional LTSM model</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D Convolutional model</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN-LSTM</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Classifier  F1 Score  Recall_score  Precision_\n",
       "0           SimpleRNN model      0.75          0.75        0.76\n",
       "1   Single LSTM layer model      0.80          0.80        0.80\n",
       "2  Bidirectional LTSM model      0.76          0.76        0.76\n",
       "3    1D Convolutional model      0.81          0.81        0.82\n",
       "4                  CNN-LSTM      0.84          0.84        0.84"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = [('SimpleRNN model',0.75,0.75,.76),\n",
    "('Single LSTM layer model',0.80,0.80,.80),\n",
    "('Bidirectional LTSM model',0.76,0.76,.76),\n",
    "('1D Convolutional model',0.81,0.81,0.82),\n",
    "('CNN-LSTM',0.84,.84,0.84)]\n",
    "label=['Classifier','F1 Score', 'Recall_score','Precision_']\n",
    "\n",
    "score_df = pd.DataFrame(data=score, columns=label)#.set_index('Classifier')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Before final commit, the best model obtained was the CNN-LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = ['Neutral','Negative','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['this experience has been the worst , want my money back'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(model2.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['i fucking hate you'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(model2.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
